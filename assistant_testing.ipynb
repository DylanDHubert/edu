{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# OpenAI Assistant Testing - TS Knee Portfolio\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Set up an OpenAI Assistant with vector store\n",
        "2. Upload the TS Knee PDF document\n",
        "3. Test the assistant with various queries\n",
        "4. Demonstrate note integration functionality\n",
        "\n",
        "## Prerequisites\n",
        "- OpenAI API key\n",
        "- Python packages: openai, python-dotenv\n",
        "- TS Knee PDF file in data/ts_knee/ directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.3.6)\n",
            "Collecting python-dotenv\n",
            "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.8.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (2.5.2)\n",
            "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
            "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "\u001b[33m  WARNING: The script dotenv is installed in '/Library/Frameworks/Python.framework/Versions/3.11/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed python-dotenv-1.1.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install openai python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "OpenAI Assistant Testing Script - TS Knee Portfolio\n",
        "Following the exact patterns from assistant.txt\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from typing_extensions import override\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv('OPENAI_API_KEY'),\n",
        "    default_headers={\"OpenAI-Beta\": \"assistants=v2\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Create Vector Store\n",
        "\n",
        "First, we'll create a vector store to hold our TS Knee document.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_assistant_and_vector_store():\n",
        "    \"\"\"Create assistant and vector store following assistant.txt pattern\"\"\"\n",
        "    print(\"ü§ñ Creating assistant...\")\n",
        "    \n",
        "    # Create assistant first (like assistant.txt)\n",
        "    assistant = client.beta.assistants.create(\n",
        "        name=\"TS Knee Portfolio Assistant\",\n",
        "        instructions=\"You are an expert medical assistant specializing in TS Knee systems. Use your knowledge base to answer questions about surgical techniques and protocols.\",\n",
        "        model=\"gpt-4o\",\n",
        "        tools=[{\"type\": \"file_search\"}],\n",
        "    )\n",
        "    print(f\"‚úÖ Assistant created: {assistant.id}\")\n",
        "    \n",
        "    # Create vector store (like assistant.txt)\n",
        "    vector_store = client.beta.vector_stores.create(name=\"TS Knee Documents\")\n",
        "    print(f\"‚úÖ Vector store created: {vector_store.id}\")\n",
        "    \n",
        "    # Ready the files for upload to OpenAI (exactly like assistant.txt)\n",
        "    file_paths = [\"data/ts_knee/TS_Knee_triathlon-TS-Brochure.pdf\"]\n",
        "    \n",
        "    # Check if file exists\n",
        "    if not Path(file_paths[0]).exists():\n",
        "        print(f\"‚ùå File not found: {file_paths[0]}\")\n",
        "        return None, None\n",
        "    \n",
        "    file_streams = [open(path, \"rb\") for path in file_paths]\n",
        "    \n",
        "    # Use the upload and poll SDK helper (exactly like assistant.txt)\n",
        "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "        vector_store_id=vector_store.id, files=file_streams\n",
        "    )\n",
        "    \n",
        "    # Print status (like assistant.txt)\n",
        "    print(f\"‚úÖ File batch status: {file_batch.status}\")\n",
        "    print(f\"‚úÖ File counts: {file_batch.file_counts}\")\n",
        "    \n",
        "    # Close file streams\n",
        "    for stream in file_streams:\n",
        "        stream.close()\n",
        "    \n",
        "    # Update assistant with vector store (exactly like assistant.txt)\n",
        "    assistant = client.beta.assistants.update(\n",
        "        assistant_id=assistant.id,\n",
        "        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        "    )\n",
        "    print(f\"‚úÖ Assistant updated with vector store\")\n",
        "    \n",
        "    return assistant, vector_store\n",
        "\n",
        "def test_basic_question(assistant):\n",
        "    \"\"\"Test basic functionality without streaming\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TESTING BASIC QUESTION\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Create a thread and attach message (like assistant.txt pattern)\n",
        "    thread = client.beta.threads.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"What is the Triathlon TS Knee system? Provide an overview.\",\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # Run the assistant\n",
        "    run = client.beta.threads.runs.create_and_poll(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=assistant.id,\n",
        "    )\n",
        "    \n",
        "    if run.status == 'completed':\n",
        "        # Get messages\n",
        "        messages = client.beta.threads.messages.list(\n",
        "            thread_id=thread.id\n",
        "        )\n",
        "        \n",
        "        # Process the latest assistant message (like assistant.txt)\n",
        "        for message in messages.data:\n",
        "            if message.role == 'assistant':\n",
        "                message_content = message.content[0].text\n",
        "                annotations = message_content.annotations\n",
        "                citations = []\n",
        "                \n",
        "                # Process citations exactly like assistant.txt\n",
        "                for index, annotation in enumerate(annotations):\n",
        "                    message_content.value = message_content.value.replace(\n",
        "                        annotation.text, f\"[{index}]\"\n",
        "                    )\n",
        "                    if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "                        cited_file = client.files.retrieve(file_citation.file_id)\n",
        "                        citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "                \n",
        "                print(\"RESPONSE:\")\n",
        "                print(message_content.value)\n",
        "                print(\"\\nCITATIONS:\")\n",
        "                print(\"\\n\".join(citations))\n",
        "                break\n",
        "    else:\n",
        "        print(f\"‚ùå Run failed with status: {run.status}\")\n",
        "\n",
        "class EventHandler():\n",
        "    \"\"\"Event handler exactly like assistant.txt\"\"\"\n",
        "    @override\n",
        "    def on_text_created(self, text) -> None:\n",
        "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
        "\n",
        "    @override\n",
        "    def on_tool_call_created(self, tool_call):\n",
        "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
        "\n",
        "    @override\n",
        "    def on_message_done(self, message) -> None:\n",
        "        # Print citations exactly like assistant.txt\n",
        "        message_content = message.content[0].text\n",
        "        annotations = message_content.annotations\n",
        "        citations = []\n",
        "        for index, annotation in enumerate(annotations):\n",
        "            message_content.value = message_content.value.replace(\n",
        "                annotation.text, f\"[{index}]\"\n",
        "            )\n",
        "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "                cited_file = client.files.retrieve(file_citation.file_id)\n",
        "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "        print(message_content.value)\n",
        "        print(\"\\n\".join(citations))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Upload PDF File\n",
        "\n",
        "Upload the TS Knee PDF to OpenAI and add it to our vector store.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def test_streaming_question(assistant):\n",
        "    \"\"\"Test streaming functionality exactly like assistant.txt\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TESTING STREAMING RESPONSE\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Create thread with message (like assistant.txt)\n",
        "    thread = client.beta.threads.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"What are the key features and benefits of the TS Knee system? Include specific technical details.\",\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # Use stream SDK helper exactly like assistant.txt\n",
        "    with client.beta.threads.runs.stream(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=assistant.id,\n",
        "        instructions=\"Please provide detailed information based on the TS Knee documentation.\",\n",
        "        event_handler=EventHandler(),\n",
        "    ) as stream:\n",
        "        stream.until_done()\n",
        "\n",
        "def test_with_notes(assistant):\n",
        "    \"\"\"Test with additional notes context\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TESTING WITH NOTES INTEGRATION\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Sample notes like in HHB system\n",
        "    notes_context = \"\"\"\n",
        "ADDITIONAL NOTES FOR REFERENCE:\n",
        "\n",
        "NOTE 1 - TS KNEE:\n",
        "TITLE: Important Surgical Consideration\n",
        "CONTENT: When using TS Knee system, always ensure proper alignment with femoral component. Double-check tibial rotation before final fixation.\n",
        "---\n",
        "\n",
        "NOTE 2 - GENERAL (SHARED):\n",
        "TITLE: Patient Safety Protocol  \n",
        "CONTENT: For all knee procedures, verify patient positioning and confirm surgical site marking before beginning.\n",
        "---\n",
        "\n",
        "USER MESSAGE: What should I consider during TS Knee surgery regarding alignment and safety?\n",
        "\"\"\"\n",
        "    \n",
        "    # Create thread with notes context\n",
        "    thread = client.beta.threads.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": notes_context,\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    # Stream response with EventHandler\n",
        "    with client.beta.threads.runs.stream(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=assistant.id,\n",
        "        instructions=\"Please address the user question using both the uploaded documents and the provided notes.\",\n",
        "        event_handler=EventHandler(),\n",
        "    ) as stream:\n",
        "        stream.until_done()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting OpenAI Assistant Test\n",
            "API Key present: Yes\n",
            "ü§ñ Creating assistant...\n"
          ]
        },
        {
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': \"The v1 Assistants API has been deprecated. Please try again by setting the header 'OpenAI-Beta: assistants=v2'. See the migration guide for more information: https://platform.openai.com/docs/assistants/migration.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_beta'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ All tests completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
            "Cell \u001b[0;32mIn[10], line 11\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create assistant and vector store\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m assistant, vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_assistant_and_vector_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m assistant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vector_store:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Failed to create assistant or vector store\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mcreate_assistant_and_vector_store\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mü§ñ Creating assistant...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create assistant first (like assistant.txt)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m assistant \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massistants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTS Knee Portfolio Assistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are an expert medical assistant specializing in TS Knee systems. Use your knowledge base to answer questions about surgical techniques and protocols.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_search\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Assistant created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00massistant\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create vector store (like assistant.txt)\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/resources/beta/assistants/assistants.py:95\u001b[0m, in \u001b[0;36mAssistants.create\u001b[0;34m(self, model, description, file_ids, instructions, metadata, name, tools, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mCreate an assistant with a model and instructions.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/assistants\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43massistant_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAssistantCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAssistant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1051\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1059\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1060\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1061\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1062\u001b[0m     )\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:842\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    835\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    841\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/_base_client.py:885\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"The v1 Assistants API has been deprecated. Please try again by setting the header 'OpenAI-Beta: assistants=v2'. See the migration guide for more information: https://platform.openai.com/docs/assistants/migration.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_beta'}}"
          ]
        }
      ],
      "source": [
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run all tests\"\"\"\n",
        "    print(\"üöÄ Starting OpenAI Assistant Test\")\n",
        "    print(f\"API Key present: {'Yes' if os.getenv('OPENAI_API_KEY') else 'No'}\")\n",
        "    \n",
        "    if not os.getenv('OPENAI_API_KEY'):\n",
        "        print(\"‚ùå Please set OPENAI_API_KEY environment variable\")\n",
        "        return\n",
        "    \n",
        "    # Create assistant and vector store\n",
        "    assistant, vector_store = create_assistant_and_vector_store()\n",
        "    \n",
        "    if not assistant or not vector_store:\n",
        "        print(\"‚ùå Failed to create assistant or vector store\")\n",
        "        return\n",
        "    \n",
        "    # Run tests\n",
        "    test_basic_question(assistant)\n",
        "    test_streaming_question(assistant)\n",
        "    test_with_notes(assistant)\n",
        "    \n",
        "    # Print environment variables for production\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PRODUCTION ENVIRONMENT VARIABLES\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"TS_KNEE_ASSISTANT_ID={assistant.id}\")\n",
        "    print(f\"TS_KNEE_VECTOR_STORE_ID={vector_store.id}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ All tests completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
